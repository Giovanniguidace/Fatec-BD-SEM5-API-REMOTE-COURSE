
# Projeto Integrador 5¬∫ Semestre

## :orange_book: <b>Desafio do PI 5¬∫ Semestre:</b>

O desafio trazido pelos professores do 5¬∫ semestre de BD era trazer uma API com a finalidade de gerenciar cursos remotamente, com base no m√©todo que foi utilizado pela Fatec SJC durante a pandemia, atrav√©s da plataforma Teams. Foi destacado a necessidade de tratar logs e demonstr√°-los em gr√°ficos, usando ETL e DW, como obrigatoriedade de mat√©rias do semestre.

### Planejamento

Para fazer o planejamento foi utilizado a metodologia de "Design Thinking". Segundo o wikipedia, Design Thinking √© o conjunto de ideias e insights para abordar problemas, relacionados a futuras aquisi√ß√µes de informa√ß√µes, an√°lise de conhecimento e propostas de solu√ß√µes.
O design thinking consiste em 5 partes ciclicas: empatia, defini√ß√£o, idea√ß√£o, prototipo, teste.

-   A primeira etapa (empatia) do primeiro ciclo foi realizada junto ao cliente.
-   A etapa de defini√ß√£o √© realizada durante as plannings do projeto.
-   A etapa de idea√ß√£o e prototipo s√£o realizadas durante a sprint e
-   A etapa de teste √© realizada sempre que um prototipo vira funcionalidade atrav√©s do fluxo de CI (continuous integration) e CD (continuous deploy/delivery) do projeto.

### Cronograma

-   16/08/2021 at√© 22/08/2021 - Kick Off do Projeto
-   30/08/2021 at√© 19/09/2021 - Sprint 1
-   20/09/2021 at√© 10/10/2021 - Sprint 2
-   18/10/2021 at√© 07/10/2021 - Sprint 3
-   08/11/2021 at√© 28/11/2021 - Sprint 4
-   29/11/2021 at√© xx/12/2021 - Sprint Apresenta√ß√£o Final
-   xx/xx/2021 at√© xx/xx/2021 - Sprint Feira de Solu√ß√µes

<a name="backlog"></a>
### :memo: BACKLOG

### USER STORIES
Na descri√ß√£o dos story cards, temos 4 personas: Aluno, Tutor, Gestor e Administrado.

- Como aluno, eu sou capaz de acessar o chat em tempo real para interagir/discutir com outros alunos e tutores;;
- Como tutor, eu sou capaz de acessar o chat do aluno para interagir/discutir com outros alunos;
- Como aluno, eu sou capaz de acessar o chatbot da plataforma para buscar orienta√ß√µes r√°pidas;
- Como aluno/tutor, eu sou capaz de acessar o sistema de LMS;
- Como gestor, eu sou capaz de adicionar/editar/excluir cursos;
- Como tutor, eu sou capaz de acessar um dashboard com pain√©is informativos espec√≠ficos para tutoria;
- Como gestor, eu sou capaz de acessar um dashboard com pain√©is informativos espec√≠ficos para gest√£o;
- Como administrador, eu sou capaz de acessar um dashboard com pain√©is informativos espec√≠ficos para administra√ß√£o;

### Requisitos Funcionais

#### :black_medium_square: Sprint 1
<strong>1</strong> - Definir as tabelas FATO do Data Warehouse;

<strong>2</strong> - Definir as dimens√µes e granularidade do Data Warehouse;

<strong>3</strong> - Desenvolver um chat em tempo real com capacidade de at√© 1000 usu√°rios simult√¢neos, capaz de gerar log das mensagens;

<strong>4</strong> - Definir ferramentas para o pipeline ETL;

#### :black_medium_square: Sprint 2

<strong>5</strong> - Criar rotinas ETL da plataforma e do chat para alimentar o DW;

<strong>6</strong> - Criar os dashboards OLAP com os indicadores requisitados;

####  :black_medium_square: Sprint 3

<strong>7</strong> - Definir os gr√°ficos para visualiza√ß√£o dos Dashboards;

<strong>8</strong> - Criar um sistema OLAP com visualiza√ß√µes (com dados de testes) diferentes para os 3 tipos de usu√°rio (Tutor, Gestor e ADM);

<strong>9</strong> - Integrar o sistema OLAP com o Data Warehouse.

<strong>10</strong> - Reestruturar os logs da aplica√ß√£o de acordo com as m√©tricas esperadas no Data Warehouse ( Ativa√ß√£o, Engajamento, Desempenho, Participa√ß√£o, Avalia√ß√£o de rea√ß√£o, Registro do tempo de participa√ß√£o no curso)

#### :white_medium_square: Sprint 4

<strong>11</strong> - Refatorar a plataforma de  LMS desenvolvida pela turma do 3¬∫ semestre de banco de dados (no primeiro semestre de 2021), para armazenar os dados dos logs em um banco de dados n√£o-relacional;

<strong>12</strong> - Criar rotinas para carregar os dados no Data Warehouse.

### :white_square_button: Requisitos n√£o Funcionais

- Documenta√ß√£o completa e clara
- Facilidade de uso
- Seguran√ßa
- Escalabilidade

# <b>:dart: Objetivo da Aplica√ß√£o Nemosys - Remote Courses:</b>


Desenvolver uma solu√ß√£o de dados voltada ao ensino √† dist√¢ncia para a gest√£o e oferta de conhecimento, dando suporte √†s mais diversas arquiteturas de aprendizagem, alinhado com os objetivos estrat√©gicos a serem alcan√ßados por cada organiza√ß√£o que atendemos como clientes. Fazer a gest√£o de logs para alimentar um Data Warehouse afim de possibilitar a melhor gest√£o estrat√©gica do neg√≥cio.

De acordo com o planejamento do time, foram levantadas as seguintes entidades:
 
- Cadastro de Alunos/Usu√°rios;
- Cadastro de Disciplinas;
- Cadastro de Aulas;
- Cadastro de Cursos;
- Cadastro de Matr√≠culas;
- Cadastro de Turmas;
- Cadastro de Notas;
- Registro de Login na plataforma;

A modelagem do Data Warehouse ficou da seguinte forma:

![image](https://raw.githubusercontent.com/api-fatec-bd/api/main/dw/untitled3.png)
Abaixo o fluxo da aplica√ß√£o:

![image](https://raw.githubusercontent.com/api-fatec-bd/api/feature/sprint_03_atualiza%C3%A7%C3%A3o/.github/Fluxo%20da%20Aplica%C3%A7%C3%A3o.png)
#

## ‚öôÔ∏è <b>Tecnologias Adotadas na Solu√ß√£o:</b>

-   Python - Para a cria√ß√£o do ETL foi definido pelo time a utiliza√ß√£o da linguagem python, por ter f√°cil implementa√ß√£o com MongoDB e PostgreSQL;
- MongoDB - Foi utilizado para registrar os Logs da aplica√ß√£o, onde posteriormente seriam tratados e enviados para o DW atrav√©s do ETL;
- PostgreSQL - Foi utilizado devido √† necessidade de ter um banco relacional para tratar tabelas de usu√°rios, aulas, disciplinas e etc...
- RocketChat - Foi utilizado como chat nas aulas, para f√°cil comunica√ß√£o entre alunos e professores;
- Docker - Para containerizar MongoDB e RocketChat;
- Data Studio - Para demonstrar o OLAP;
- Linux Ubuntu Server - Utilizado em 2 inst√¢ncias para manter as aplica√ß√µes escal√°veis e seguras. Foi utilizado o crontab do linux para criar rotinas de extra√ß√£o do ETL;

## :wrench: <b>Contribui√ß√µes individuais/pessoais</b>

A minha contribui√ß√£o neste projeto foi tratar o ETL, onde a meta era extrair dados do MongoDB, prepar√°-los de acordo com o planejado pela equipe de DW e carreg√°-lo em um banco relacional(PostgreSQL).

Inicialmente levantamos v√°rias ferramentas de ETL, no qual algumas delas seriam: 

- Data Stage;
- Decision Streem;
- ETL Extract;
- OWB - Oracle Warehouse Builder;
- Apache Airflow;

Ap√≥s os testes realizados em cada uma destas ferramentas, chegamos na conclus√£o de utilizar o Apache Airflow, mas era algo muito extenso e a nossa necessidade n√£o era algo que necessitasse algo t√£o poderoso. 

Ap√≥s alguns debates, planejamos "codar" o ETL na m√£o e atrav√©s da linguagem Python.

Foram extraidos os Logs abaixo para o modelo dimensional:
- Dim Aula;
- Dim Curso;
- Dim Disciplina;
- Dim Turma;
- Dim Usu√°rios;

Foram extraidos e implementados em tabelas fato os seguintes Logs:
- Acessos;
- Aluno presente nas aulas e quanto tempo;
- Registro de mensagens no chat e tempo de dura√ß√£o;
- Matriculas realziadas em determinado per√≠odo;
- Notas de cada aluno e an√°lise peri√≥dica;
- Login e Logout nos chats das aulas;


Inicialmente foram criadas as conex√µes com o MongoDB e PostgreSQL:

```python
def mongoConnection():

	mongo_conn = MongoClient('mongodb://157.245.243.16:3004/?retryWrites=false')
	return mongo_conn

def postgreeConnection():

	sql_conn = psycopg2.connect(host='157.245.243.16', database='PROJETO_API_NEMO',
	user='username', password='password')
	sql_conn.autocommit = True
	return sql_conn.cursor()
```

Posteriormente realizamos as extra√ß√µes, tratamento e carregamento dos dados em destinos criados para o DW, como o c√≥digo de exemplo abaixo:

```python
import sys
sys.path.append("..")
from connections import connections
from aux_functions import aux_functions
from datetime import datetime
import psycopg2

################################################################# INSERT FACT USUARIO CHAT #################################################################

def insertFactUsuarioChat(id_usuario_chat, id_usuario, id_chat, data_login, data_logoff, quantidade_mensagens, data_ultima_msg, tempo_participacao):
	try:
		connection = connections.conexaoBanco()
		cursor = connection.cursor()
		comando_insert = """ INSERT INTO fact_usuario_chat (id_usuario_chat, id_usuario, id_chat, data_login, data_logoff, quantidade_mensagens, data_ultima_msg, tempo_participacao) VALUES (%s,%s,%s,%s, %s, %s, %s, %s)"""
		values = (id_usuario_chat, id_usuario, id_chat, data_login, data_logoff, quantidade_mensagens, data_ultima_msg,
tempo_participacao)
		cursor.execute(comando_insert, values)
		connection.commit()
		print("INSERT FACT USUARIO CHAT OK: ", values)
		return "Usuario Chat inserido com sucesso!"
		except (Exception, psycopg2.Error) as error:
		print("Failed to insert record into mobile table", error)
		return error
	finally:
		if connection:
			cursor.close()
			connection.close()
		  print("PostgreSQL connection is closed")

##########################################################################################################################################################

# CRIAR FILTRO PARA ALIMENTAR TABELA FACT_USUARIO_CHAT

"""""""""

Campos: ID_USUARIO_CHAT; ID_USUARIO; ID_CHAT; DATA_LOGIN; DATA_LOGOFF; TEMPO_PARTICIPACAO; DATA_ULTIMA_MSG; QUANTIDADE_MENSAGENS;

"""""""""

def filtroFactUsuarioChat():
		collection_usuarios = connections.mongoConnection()['Logs']['Usuario'].find()
		collection_message = connections.mongoConnection()['rocketchat']['rocketchat_message']
		id_usuario_chat = 0
		for usuario in collection_usuarios:
			mensagens_usuario = list(collection_message.find({'username': usuario['USERNAME'], "etl": {'$exists': False}}))
			#print("mensagens_usuario: ", mensagens_usuario)
			#PRIMEIRA MENSAGEM; ULTIMA MENSAGEM, TEMPO DURACAO; DA ROOM SELECIONADA NO USU√ÅRIO SELECIONADO
			salas = ["GENERAL", "SALA2", "SALA1"]
			for sala in salas:
				print("Sala: ", sala)
				vetor_mensagensPorSalaUsuario = []
				for mensagemUsuario in mensagens_usuario:
					print("SalamensagemUsuario: ", mensagemUsuario['rid'])
					if mensagemUsuario['rid'] == sala:
						vetor_mensagensPorSalaUsuario.append(mensagemUsuario)
					else:
						None
		if vetor_mensagensPorSalaUsuario != []:
			print("Teste vetor_mensagensPorSalaUsuario: ", vetor_mensagensPorSalaUsuario)
			id_usuario_chat = id_usuario_chat + 1
			data_login = datetime.strptime(vetor_mensagensPorSalaUsuario[0]['_updateAt'], '%d-%m-%Y %H:%M:%S')
			data_logoff = datetime.strptime(vetor_mensagensPorSalaUsuario[-1]['_updateAt'], '%d-%m-%Y %H:%M:%S')
			tempo_participacao = (data_logoff - data_login).total_seconds() / 60
			tempo_participacao = "{:.2f}".format(tempo_participacao)
			# QUANTIDADE DE MENSAGENS
			quantidade_mensagens = len(vetor_mensagensPorSalaUsuario)
			print("data_login: ", data_login)
			print("data_logoff: ", data_logoff)
			print("tempo_participacao: ", tempo_participacao)
			print("quantidade_mensagens: ", quantidade_mensagens)
			print("sala: ", vetor_mensagensPorSalaUsuario[0]['rid'])
			result = insertFactUsuarioChat(id_usuario_chat, usuario['IDUSUARIO'], vetor_mensagensPorSalaUsuario[0]['rid'],
			data_login, data_logoff, quantidade_mensagens, data_logoff, tempo_participacao)

			for mensagemPorSala in vetor_mensagensPorSalaUsuario:
				# INSER√á√ÉO DA FLAG 1 PARA DADO INSERIDO CORRETAMENTE E FALHA 0
				_id = mensagemPorSala['_id']
				if result == "Usuario Chat inserido com sucesso!":
					aux_functions.atualizaFlag(_id, 'rocketchat', 'rocketchat_message', 1)
				elif "duplicate key value violates unique constraint" in str(result):
					aux_functions.atualizaFlag(_id, 'rocketchat', 'rocketchat_message', 1)
				else:
					aux_functions.atualizaFlag(_id, 'rocketchat', 'rocketchat_message', 0)

filtroFactUsuarioChat()
```

## üß† <b>Aprendizados Efetivos</b>

* Aprendizado sobre ETL e Data Warehouse: Neste projeto foram divididos times que iriam ficar com determinadas tarefas para a conclus√£o do projeto, mas ao mesmo tempo auxiliando outros times caso tivessem problema. Devido eu ter ficado com a parte de ETL, foi poss√≠vel entender como √© feito o processo e cria√ß√£o, desde a extra√ß√£o dos dados at√© o preparo e envio para a equipe de DW. Tivemos a mat√©ria de DW e isso auxiliou muito no aprendizado. Aprendemos diversas ferramentas de ETL, e tamb√©m a cria√ß√£o de um ETL do zero atrav√©s da linguagem Python. Foi poss√≠vel aprender sobre task scheduler, no qual √© utilizado para ser como um gatilho de fun√ß√µes da aplica√ß√£o, com hor√°rios e dias pr√©-definidos.

* Aprendizado com MongoDB: Particularmente j√° havia trabalhado com MondoDB em outros projetos, por√©m, desta vez, foi pensando em extra√ß√£o e tratamento de Logs, onde √© preciso criar uma an√°lise bem feita para que a informa√ß√£o passada n√£o seja incorreta. Agregou muito em minhas skills, pois trabalho como SysAdmin e a viv√™ncia com Logs √© bem alta.

* Aprendizado em Data Warehouse: Devido ao contato com a equipe de DW, foi poss√≠vel aprender muito sobre as tabelas Dimens√£o e tabelas Fato. Acrescentou muito no conhecimento e que isso iria melhorar o conhecimento em OLAP. 

* Testes unit√°rios: Como parte das requisi√ß√µes de entrega, era necess√°rio criar os testes unit√°rios, onde foi poss√≠vel aprender sobre TTL.

